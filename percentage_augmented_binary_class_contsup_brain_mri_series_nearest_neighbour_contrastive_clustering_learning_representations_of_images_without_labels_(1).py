# -*- coding: utf-8 -*-
"""PERCENTAGE_Augmented_Binary_Class_CONTsUP_BRAIN_MRI_Series_Nearest_Neighbour_Contrastive_Clustering_Learning_Representations_Of_Images_Without_labels (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CguV5YMZwbUUS7FkOIYQDI_JEVBnCBNF
"""

from google.colab import drive
drive.mount('/content/drive')

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
import keras
import random
import math
import scipy
import tensorflow as tf
from pathlib import Path
from tensorflow.keras import applications
from tensorflow.keras import layers
from tensorflow.keras import losses
from tensorflow.keras import optimizers
from tensorflow.keras import metrics
from tensorflow.keras import Model
from tensorflow.keras.applications import resnet
import skimage.io as io
import scipy.ndimage as nd
from skimage.transform import rotate, AffineTransform, warp
from skimage.util import random_noise
from skimage.filters import gaussian
from scipy.spatial.distance import pdist
import cv2
import pickle
from glob import glob
from tqdm import tqdm
import gc
import time

"""## Initializing Variables

The varibales include file paths as well as other variables
"""

target_shape = (200, 200)
batch_size = 32

num_classes =2
mode ='easy'
dataset_type='cifar-10'
augmentation_mode='_original_images'

!pip install image-classifiers==1.0.0b1
!pip install git+https://github.com/qubvel/classification_models.git

"""## Reading and Preprocessing Training Datasets"""

!pip install -U --no-cache-dir gdown --pre

!gdown https://drive.google.com/uc?id=1RK-qLscrh8WirgwSxOcTbq5_3F3UcpTa
!unzip "/content/images_binary.zip"

training_paths = glob('/content/training_images/*.jpg')
testing_paths = glob('/content/testing_images/*.jpg')

def get_label_from_path(path, pos=2):
  arr_split= path.split('/')
  return arr_split[len(arr_split)-pos]

def get_labels(paths_array):
    labels=[]
    for paths_and_labels in paths_array:
      tot_lab= get_label_from_path(paths_and_labels,pos = 1)
      labels.append(tot_lab.split('@')[0])
    return labels

training_labels= get_labels(training_paths)
testing_labels= get_labels(testing_paths)

pd.Series(training_labels).value_counts()

pd.Series(testing_labels).value_counts()

testing_labels

def read_preprocess_and_augment_image(filename):
    '''
      Accepts a file path and returns the image stored in the file path
    '''
    image_string = tf.io.read_file(filename)
    image = tf.image.decode_jpeg(image_string, channels=3)
    image = tf.image.convert_image_dtype(image, tf.float32)
    image = tf.image.resize(image, target_shape,method='bilinear')
    ##image = alter_image(image)
    aug_image = generate_augmentation(image)
    return aug_image

def read_and_preprocess_image(filename):
    image_string = tf.io.read_file(filename)
    image = tf.image.decode_jpeg(image_string, channels=3)
    image = tf.image.convert_image_dtype(image, tf.float32)
    image = tf.image.resize(image, target_shape,method='bilinear')
    return image

def generate_augmentation(image):
    '''
     Inputs an image and returns its augmentation
    '''
    augmentations_mode=['Resized Crop','Random Brightness','Random_Contrast','Gaussian Blur']
    aug_mode_idx= random.randint(0,len(augmentations_mode))
    aug_image= image

    aug_image = tf.image.random_crop(image, size=[120,120,3])
    aug_image = tf.image.resize(aug_image, target_shape, method='bilinear')

    aug_image= tf.image.random_brightness(aug_image,0.3)
    aug_image= tf.image.random_contrast(aug_image, 0.3, 0.7)
    aug_image= tf.image.random_jpeg_quality(aug_image,min_jpeg_quality=10, max_jpeg_quality = 100)
    return aug_image
    '''
    print(aug_mode_idx)
    if(aug_mode_idx==0):
      aug_image = tf.image.random_crop(image, size=[120,120,3])
      aug_image = tf.image.resize(aug_image, target_shape, method='bilinear')

    elif(aug_mode_idx==1):
      aug_image= tf.image.random_brightness(image,0.5)

    elif(aug_mode_idx==2):
      aug_image= tf.image.random_contrast(image, 0.3, 0.7)

    elif(aug_mode_idx==3):
      aug_image= tf.image.random_jpeg_quality(image,min_jpeg_quality=6, max_jpeg_quality = 7)
    
    return aug_image
    '''

image_paths= training_paths

dataset_len= len(image_paths)

print(dataset_len)

image_count = dataset_len

dataset_a = tf.data.Dataset.from_tensor_slices(image_paths)
dataset_b = tf.data.Dataset.from_tensor_slices(image_paths)

dataset_a = dataset_a.map(read_preprocess_and_augment_image)
dataset_b = dataset_b.map(read_preprocess_and_augment_image)

dataset= tf.data.Dataset.zip((dataset_a,dataset_b))

##dataset= dataset.shuffle(10000)

train_dataset = dataset.take(round(image_count))
val_dataset = dataset.skip(round(image_count * 0.9))

train_dataset = train_dataset.batch(batch_size, drop_remainder=True)
train_dataset = train_dataset.prefetch(batch_size)

val_dataset = val_dataset.batch(batch_size, drop_remainder=True)
val_dataset = val_dataset.prefetch(batch_size)



"""## Visualising the Dataset"""

def visualize_dataset(anchor, positive):
    """Visualize samples of dataset """

    def show(ax, image):
        ax.imshow(image)
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)

    fig = plt.figure(figsize=(15, 4))

    axs = fig.subplots(2, 8)
    for i in range(8):
        cv2.imwrite(f'aug_1_{i}.jpg', anchor[i]*255.0)
        cv2.imwrite(f'aug_2_{i}.jpg', positive[i]*255.0)
        show(axs[0, i], anchor[i])
        show(axs[1, i], positive[i])

data_for_visualization= list(train_dataset.take(10).as_numpy_iterator())

visualize_dataset(*data_for_visualization[0])

ctr=0
for path in image_paths[:batch_size]:
  img= cv2.imread(path)
  cv2.imwrite(f'original_image_{ctr}.jpg',img)
  ctr+=1

visualize_dataset(*data_for_visualization[1])

"""## Initializing the Instance Level Contrastive Head"""

embedding_layer_output_dimension = 128

from classification_models.tfkeras import Classifiers

ResNet18, preprocess_input = Classifiers.get('resnet18')
base_cnn = ResNet18(target_shape+(3,), weights=None, include_top=False)

'''
Base CNN and the EMBEDDING LAYER
'''
base_cnn = resnet.ResNet50(
    weights='imagenet', input_shape=target_shape + (3,), include_top=False
)

base_cnn.summary()

for layer in base_cnn.layers:
    layer.trainable = True

'''
last_layer1 = base_cnn.get_layer('stage4_unit1_bn1')
last_output1 = last_layer1.output
x1 = tf.keras.layers.Flatten()(last_output1)
x1 = tf.keras.layers.Dropout(0.4)(x1)
x1 = tf.keras.layers.Dense(1024, activation='relu')(x1)

last_layer3 = base_cnn.get_layer('stage4_unit2_conv2') #get the layer
last_output3 = last_layer3.output                       #get the layer output
x3 = tf.keras.layers.Flatten()(last_output3)
x3= tf.keras.layers.Dropout(0.4)(x3)
x3 = tf.keras.layers.Dense(1024, activation='relu')(x3)  

from keras.layers import concatenate
y = concatenate([x1, x3])
y= tf.keras.layers.BatchNormalization()(y)
y = tf.keras.layers.Flatten()(y)
y= tf.keras.layers.Dropout(0.4)(y)

x2 = tf.keras.layers.Dense(2, activation='softmax')(y)
supervised_nn = Model(base_cnn.input, x2, name="Embedding")
'''
last_layer1 = base_cnn.get_layer('conv5_block3_3_bn')
last_output1 = last_layer1.output
x1 = tf.keras.layers.Flatten()(last_output1)
x1 = tf.keras.layers.Dropout(0.4)(x1)
x1 = tf.keras.layers.Dense(1024, activation='relu')(x1)

last_layer3 = base_cnn.get_layer('conv5_block3_out') #get the layer
last_output3 = last_layer3.output                       #get the layer output
x3 = tf.keras.layers.Flatten()(last_output3)
x3= tf.keras.layers.Dropout(0.4)(x3)
x3 = tf.keras.layers.Dense(1024, activation='relu')(x3)  

from keras.layers import concatenate
y = concatenate([x1, x3])
y= tf.keras.layers.BatchNormalization()(y)
y = tf.keras.layers.Flatten()(y)
y= tf.keras.layers.Dropout(0.4)(y)

x2 = tf.keras.layers.Dense(2, activation='softmax')(y)
supervised_nn = Model(base_cnn.input, x2, name="Embedding")

base_cnn.summary()

"""## Supervised Training"""

y_values= pd.get_dummies(pd.DataFrame(training_labels))

y_values= y_values.values

from tensorflow.keras.optimizers import SGD
supervised_nn.compile(loss='categorical_crossentropy',
            optimizer=SGD(learning_rate=0.0001, momentum=0.95, nesterov=True,clipnorm=1.0),
            metrics=['accuracy'])

supervised_train_x = tf.data.Dataset.from_tensor_slices(image_paths)
supervised_train_x= supervised_train_x.map(read_and_preprocess_image)
supervised_train_y = tf.data.Dataset.from_tensor_slices(y_values)
supervised_dataset= tf.data.Dataset.zip((supervised_train_x, supervised_train_y))
supervised_dataset = supervised_dataset.batch(batch_size, drop_remainder= True)

supervised_train_x= []
for path in training_paths:
    img = cv2.imread(path)
    img = cv2.resize(img, (200, 200))
    supervised_train_x.append(img)
supervised_train_x= np.array(supervised_train_x, dtype='float32')

gc.collect()

supervised_train_x.shape

y_values.shape

supervised_nn.fit(supervised_train_x,y_values,batch_size=16, epochs=50)

## Allowing only the last few layers to be trainable
'''
trainable = False
for layer in base_cnn.layers:
    ##if layer.name == "conv5_block1_out":
    if layer.name == "conv5_block1_out":
        trainable = True
    layer.trainable = trainable
'''

for layer in base_cnn.layers:
  layer.trainable= True

last_layer1 = base_cnn.get_layer('conv5_block3_3_bn')
last_output1 = last_layer1.output
x1 = tf.keras.layers.Flatten()(last_output1)
##x1 = tf.keras.layers.Dropout(0.4)(x1)
x1 = tf.keras.layers.Dense(1024, activation='relu')(x1)

last_layer3 = base_cnn.get_layer('conv5_block3_out') #get the layer
last_output3 = last_layer3.output                       #get the layer output
x3 = tf.keras.layers.Flatten()(last_output3)
##x3= tf.keras.layers.Dropout(0.4)(x3)
x3 = tf.keras.layers.Dense(1024, activation='relu')(x3)  

from keras.layers import concatenate
y = concatenate([x1, x3])
y= tf.keras.layers.BatchNormalization()(y)
y = tf.keras.layers.Flatten()(y)
##y= tf.keras.layers.Dropout(0.5)(y)

x2 = tf.keras.layers.Dense(128, activation='relu')(y)
embedding_layer = Model(base_cnn.input, x2, name="Embedding")

flatten = layers.Flatten()(base_cnn.output)
dense1 = layers.Dense(512, activation="relu")(flatten)
dense1 = layers.Dense(512, activation="relu")(dense1)
dense1 = layers.BatchNormalization()(dense1)
dense2 = layers.Dense(256, activation="relu")(dense1)
dense2= layers.BatchNormalization()(dense2)
dense3= layers.Dense(256, activation='relu')(dense2)
dense3= layers.Dropout(0.4)(dense3)
output = layers.Dense(embedding_layer_output_dimension)(dense3)

embedding_layer = Model(base_cnn.input, output, name="Embedding")

!gdown https://drive.google.com/uc?id=1q78n119FOrQZwHUfXCzQN4H1uW5StCuT

embedding_layer= tf.keras.models.load_model('/content/model_with_dropout_2.h5', compile=False)

!gdown https://drive.google.com/uc?id=11hPhNR5DArNPDJaaxBeCu6B9EOFoaVKN

added_layer= tf.keras.layers.Dense(32,activation = 'relu')(embedding_layer.output)

embedding_layer2= Model(embedding_layer.input, added_layer, name="embedding_layer2")

#embedding_layer2 = Model(embedding_layer.input, added_layer, name='added_layer')
!gdown https://drive.google.com/uc?id=10kBG1ILbOHuYMEHklo8m84pi7H-HOiyK
!unzip /content/encoder_model.zip

embedding_layer2= tf.keras.models.load_model('/content/encoder_model', compile= False)
#embedding_layer2 = Model(embedding_layer.input, added_layer, name='added_layer')

embedding_layer2.summary()

embedding_layer2 = tf.keras.models.model_from_json(open('/content/encoder_model').read())
#embedding_layer2.load_weights(os.path.join(os.path.dirname('/content/encoder_model'), 'model_weights.h5'))

"""## The Contrastive Clustering Model"""

class Contrastive_loss:
  
    def __init__(self, temperature):
      self.temperature=temperature
    
    '''

    def compute_loss(self,xi, xj,  tau=0.5, normalize=True):

        x = tf.keras.backend.concatenate((xi, xj), axis=0)

        sim_mat = tf.keras.backend.dot(x, tf.keras.backend.transpose(x))

        if normalize:
            sim_mat_denom = tf.keras.backend.dot(tf.keras.backend.l2_normalize(x, axis=1).unsqueeze(1), tf.keras.backend.l2_normalize(x, axis=1).unsqueeze(1).T)
            sim_mat = sim_mat / sim_mat_denom.clamp(min=1e-8)

        sim_mat = tf.keras.backend.exp(sim_mat /tau)

        if normalize:
            sim_mat_denom = tf.keras.backend.l2_normalize(xi, dim=1) * tf.keras.backend.l2_normalize(xj, axis=1)
            sim_match = tf.keras.backend.exp(tf.keras.backend.sum(xi * xj, axis=-1) / sim_mat_denom / tau)
        else:
            sim_match = tf.keras.backend.exp(tf.keras.backend.sum(xi * xj, axis=-1) / tau)

        sim_match = tf.keras.backend.concatenate((sim_match, sim_match), axis=0)

        norm_sum = tf.keras.backend.exp(tf.keras.backend.ones(tf.keras.backend.shape(x)[0]) / tau)

        return tf.math.reduce_mean(-tf.keras.backend.log(sim_match / (tf.keras.backend.sum(sim_mat, axis=-1) - norm_sum)), name='contrastive_loss')
      '''
    '''


    def compute_loss(self,zi, zj, tau=0.5):
         Calculates the contrastive loss of the input data using NT_Xent. The
        equation can be found in the paper: https://arxiv.org/pdf/2002.05709.pdf
        (This is the Tensorflow implementation of the standard numpy version found
        in the NT_Xent function).
        
        Args:
            zi: One half of the input data, shape = (batch_size, feature_1, feature_2, ..., feature_N)
            zj: Other half of the input data, must have the same shape as zi
            tau: Temperature parameter (a constant), default = 1.

        Returns:
            loss: The complete NT_Xent constrastive loss
        
        z = tf.keras.backend.concatenate((zi, zj), axis=0)
        loss = 0
        for k in range(zi.shape[0]):
            # Numerator (compare i,j & j,i)
            i = k
            j = k + zi.shape[0]
            # Instantiate the cosine similarity loss function
            cosine_sim = tf.keras.losses.CosineSimilarity(axis=-1, reduction=tf.keras.losses.Reduction.NONE)
            sim = tf.squeeze(- cosine_sim(tf.reshape(z[i], (1, -1)), tf.reshape(z[j], (1, -1))))
            numerator = tf.math.exp(sim / tau)

            # Denominator (compare i & j to all samples apart from themselves)
            sim_ik = - cosine_sim(tf.reshape(z[i], (1, -1)), z[tf.range(z.shape[0]) != i])
            sim_jk = - cosine_sim(tf.reshape(z[j], (1, -1)), z[tf.range(z.shape[0]) != j])
            denominator_ik = tf.reduce_sum(tf.math.exp(sim_ik / tau))
            denominator_jk = tf.reduce_sum(tf.math.exp(sim_jk / tau))

            # Calculate individual and combined losses
            loss_ij = - tf.math.log(numerator / denominator_ik)
            loss_ji = - tf.math.log(numerator / denominator_jk)
            loss += loss_ij + loss_ji
        
        # Divide by the total number of samples
        loss /= z.shape[0]

        return loss
      '''
    '''
    def compute_loss(self, embeddings_a, embeddings_b, temperature= 0.5):
      
      sum_loss=tf.Variable(0.0)
      for i in range(batch_size):
        z_i_a= embeddings_a[i]
        z_i_b= embeddings_b[i]

        numr = tf.math.exp(tf.losses.cosine_similarity(z_i_a,z_i_b)/temperature)

        denomr_a= self.compute_denom_loss(z_i_a, embeddings_a, embeddings_b,temperature)
        
        denomr_b = self.compute_denom_loss(z_i_b, embeddings_b, embeddings_a, temperature)

        ins_loss_a= -1* tf.math.log(numr/denomr_a)
        ins_loss_b = -1* tf.math.log(numr/denomr_b)
        sum_loss= sum_loss+ ins_loss_a+ins_loss_b
      return sum_loss/(2*batch_size)

    def compute_denom_loss(self,vec, embeddings_a, embeddings_b, temperature, to_transpose=False):

      if(to_transpose):
        embeddings_a= tf.transpose(embeddings_a)
        embeddings_b= tf.transpose(embeddings_b)

      first_part= tf.math.exp(tf.losses.cosine_similarity(vec,embeddings_a)/temperature)
      second_part= tf.math.exp(tf.losses.cosine_similarity(vec, embeddings_b)/temperature)

      sum_parts = tf.reduce_sum(first_part+second_part)

      return sum_parts
    '''
    
    def compute_loss(self, hidden1, hidden2, temperature= 0.5):
      weights=1.0
      LARGE_NUM=1e9
      hidden1_large = hidden1
      hidden2_large = hidden2
      labels = tf.one_hot(tf.range(batch_size), batch_size * 2)
      masks = tf.one_hot(tf.range(batch_size), batch_size) 

      logits_aa = tf.matmul(hidden1, hidden1_large, transpose_b=True) / temperature
      logits_aa = logits_aa - masks * LARGE_NUM
      logits_bb = tf.matmul(hidden2, hidden2_large, transpose_b=True) / temperature
      logits_bb = logits_bb - masks * LARGE_NUM
      logits_ab = tf.matmul(hidden1, hidden2_large, transpose_b=True) / temperature
      logits_ba = tf.matmul(hidden2, hidden1_large, transpose_b=True) / temperature

      ##loss_a = tf.losses.softmax_cross_entropy(
          ##labels, tf.concat([logits_ab, logits_aa], 1), weights=weights)
      ##loss_b = tf.losses.softmax_cross_entropy(
          ##labels, tf.concat([logits_ba, logits_bb], 1), weights=weights)
      ##loss = loss_a + loss_b

      loss_a = tf.nn.softmax_cross_entropy_with_logits(
          labels, tf.concat([logits_ab, logits_aa], 1))
      loss_b = tf.nn.softmax_cross_entropy_with_logits(
          labels, tf.concat([logits_ba, logits_bb], 1))
      
      loss = tf.reduce_mean(loss_a + loss_b)

      return loss

class Contrastive_Clustering_Model:

    def __init__(self,base_network, len_mask=5000):
      self.base_network= base_network
      self.MOD= 1e30 + 7.0
      self.Contrastive_loss= Contrastive_loss(temperature=0.5)
      self.loss_tracker = metrics.Mean(name="loss")

    def fit(self, dataset,epochs=5):
      loss_logs= open("loss_logs.txt",'w')
      loss_logs.write(" starting ")
      loss_logs.close()

      for epoch in range(epochs):

        print("Running epoch -->   "+ str(epoch+1))
             
        sum_loss=[]
        for idx, mini_batch in tqdm(enumerate(dataset)):
          loss= self.__train_step(mini_batch, idx+1, epoch+1,int(dataset_len*0.45/32.0))
          ##print(loss['loss'])
          sum_loss.append(loss['loss'])
          loss_logs= open("loss_logs.txt",'a')
          loss_logs.write("  ||  "+str(loss['loss'].numpy())+"   ||  ")
          loss_logs.write("\n")
          loss_logs.close()

    def compile(self, optimizer=optimizers.Adam(0.0003,epsilon=0.1)):
      self.optimizer= optimizer
    
    def __train_step(self,data, iteration,epoch, max_iterations):

      w_contrastive=2.0
      if(epoch==1 or iteration < (max_iterations/2)):
        w_clustering=0.0
      else:
        w_clustering=10.0

      with tf.GradientTape() as tape:
        type_1_embeddings_contrastive= self.call_contrastive(data[0])
        type_2_embeddings_contrastive= self.call_contrastive(data[1])

        contrastive_loss= self.Contrastive_loss.compute_loss(type_1_embeddings_contrastive, type_2_embeddings_contrastive)

        loss = w_contrastive* contrastive_loss

      print('\n')
      print("loss -->  "+ str(loss))
      
      gradients= tape.gradient(loss, self.base_network.trainable_weights)
      
      self.optimizer.apply_gradients(
          zip(gradients, self.base_network.trainable_weights)
      )
  
      self.loss_tracker.update_state(loss)
      return {"loss": self.loss_tracker.result()}
    
    def increasing_alpha(self, alpha):
      return alpha

    def decreasing_alpha(self, alpha):
      return alpha

    def call(self,data):
      return self.base_network(data)

    def call_contrastive(self, data):
      base_cnn_output= self.call(data)
      return base_cnn_output

    def get_distances_mat_vec(self,mat,vec):
      dist_mat= tf.square(mat-vec)
      sum_squared_dist= tf.math.reduce_sum(dist_mat, axis=1)
      distances = tf.math.sqrt(sum_squared_dist)
      sum_distances = tf.cast(tf.math.reduce_sum(distances), dtype = tf.double)
      return sum_distances

"""## Training Phase"""

contrastiveClusteringModel=  Contrastive_Clustering_Model(base_network=embedding_layer2)
##contrastive_model_2.compile(optimizer=optimizers.Adam(0.000001, epsilon=0.1))
##contrastive_model_2.fit(train_dataset, epochs=2)

gc.collect()

contrastiveClusteringModel.compile()
contrastiveClusteringModel.fit(dataset=train_dataset, epochs=30)

embedding_layer2.save('/content/drive/MyDrive/embedding_layer2.h5')

embedding_layer.save_weights('embedding_layer_weights2')



"""## Supervised Training of Representations"""

clustering_dataset_batch = 100

total_num_images= len(image_paths)

gc.collect()

from tensorflow.keras.optimizers import SGD
from sklearn.metrics import precision_recall_fscore_support
'''supervised_classifier.compile(loss='categorical_crossentropy',
            optimizer=SGD(learning_rate=0.01, momentum=0.95, nesterov=True,clipnorm=1.0),
            metrics=['accuracy'])'''
f1_scores= []
accuracies=[]

def get_dataset(image_paths,percentage):
    total_num_images= len(image_paths)
    clustering_dataset= tf.data.Dataset.from_tensor_slices(image_paths[:round(percentage*total_num_images)])
    print(len(image_paths[:round(percentage*total_num_images)]))
    clustering_dataset= clustering_dataset.map(read_and_preprocess_image)
    clustering_dataset= clustering_dataset.batch(clustering_dataset_batch, drop_remainder= False)

    return clustering_dataset

def get_embeddings(clustering_dataset):
    clustering_datapoints=[]
    ctr=0
    for datapoint_batch in clustering_dataset:
      embeddings= contrastiveClusteringModel.call_contrastive(datapoint_batch)
      for datapoint in embeddings:
        clustering_datapoints.append(datapoint.numpy())
      ctr+=1

    return np.array(clustering_datapoints)

def get_supervised_classifier2():
  embedding_layer= tf.keras.models.load_model('/content/sup_class_bin.h5', compile= False)
  added_layer= tf.keras.layers.Dense(32,activation = 'relu')(embedding_layer.output)
  embedding_layer2= Model(embedding_layer.input, added_layer,name='embedding_layer')
  return embedding_layer2

def get_supervised_classifier():
    supervised_classifier = tf.keras.Sequential()
    supervised_classifier.add(tf.keras.layers.Dense(256, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(256, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(128))
    supervised_classifier.add(tf.keras.layers.Dense(128, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(64, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(32, activation="relu"))
    supervised_classifier.add(tf.keras.layers.Dropout(0.4))
    supervised_classifier.add(tf.keras.layers.Dense(16, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(num_classes,activation='softmax'))

    return supervised_classifier


test_dataset = tf.data.Dataset.from_tensor_slices(testing_paths)

test_dataset= test_dataset.map(read_and_preprocess_image)
test_dataset= test_dataset.batch(batch_size)

test_embeddings_output =[]
ctr=0
for mini_batch in test_dataset:
  test_embeddings= contrastiveClusteringModel.call_contrastive(mini_batch)
  for vec in test_embeddings:
    test_embeddings_output.append(vec.numpy())
  ##if(ctr>10):
    ##break
  ctr+=1

def encode_values_to_numbers(actual_labels):
    return np.where(pd.get_dummies(actual_labels).values ==1)[1]

test_embeddings_output= np.array(test_embeddings_output)
##x_true= pd.get_dummies(testing_labels).values
#percentages=[0.3, 0.5, 0.6, 0.8,0.9,1.0]
percentages= [1.0]
for percentage in percentages:
    gc.collect()
    clustering_dataset = get_dataset(image_paths, percentage)
    clustering_datapoints= get_embeddings(clustering_dataset)
    train_cluster_dataset= np.array(clustering_datapoints)

    train_y= pd.get_dummies(training_labels[:round(percentage*total_num_images)]).values

    supervised_classifier= get_supervised_classifier()

    supervised_classifier.compile(loss='categorical_crossentropy',
                optimizer='adam',
                metrics=['accuracy'])
    history = supervised_classifier.fit(train_cluster_dataset,train_y,batch_size= 32,epochs= 10000,validation_split=0.2)

    evaluate_output = supervised_classifier.evaluate(test_embeddings_output, pd.get_dummies(testing_labels).values ==1)
    print(evaluate_output)
    accuracies.append(evaluate_output[1])

    predictions = supervised_classifier(test_embeddings_output)

    e2= encode_values_to_numbers(testing_labels)

    e1= []
    for i in predictions:
        e1.append(np.where(i==max(i))[0][0])

    output = precision_recall_fscore_support(e1,e2, average='weighted')
    print(output[2])
    f1_scores.append(output[2])
    ##accuracies.append()

from tensorflow.keras.optimizers import SGD
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import RocCurveDisplay
'''supervised_classifier.compile(loss='categorical_crossentropy',
            optimizer=SGD(learning_rate=0.01, momentum=0.95, nesterov=True,clipnorm=1.0),
            metrics=['accuracy'])'''
f1_scores= []
accuracies=[]

def get_dataset(image_paths,percentage):
    total_num_images= len(image_paths)
    clustering_dataset= tf.data.Dataset.from_tensor_slices(image_paths[:round(percentage*total_num_images)])
    print(len(image_paths[:round(percentage*total_num_images)]))
    clustering_dataset= clustering_dataset.map(read_and_preprocess_image)
    clustering_dataset= clustering_dataset.batch(clustering_dataset_batch, drop_remainder= False)

    return clustering_dataset

def get_embeddings(clustering_dataset):
    clustering_datapoints=[]
    ctr=0
    for datapoint_batch in clustering_dataset:
      embeddings= contrastiveClusteringModel.call_contrastive(datapoint_batch)
      for datapoint in embeddings:
        clustering_datapoints.append(datapoint.numpy())
      ctr+=1

    return np.array(clustering_datapoints)

def get_supervised_classifier2():
  embedding_layer= tf.keras.models.load_model('/content/sup_class_bin.h5', compile= False)
  #added_layer= tf.keras.layers.Dense(32,activation = 'relu')(embedding_layer.output)
  #embedding_layer2= Model(embedding_layer.input, added_layer,name='embedding_layer')
  return embedding_layer

def get_supervised_classifier():
    supervised_classifier = tf.keras.Sequential()
    supervised_classifier.add(tf.keras.layers.Dense(256, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(256, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(128))
    supervised_classifier.add(tf.keras.layers.Dense(128, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(64, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(32, activation="relu"))
    supervised_classifier.add(tf.keras.layers.Dropout(0.4))
    supervised_classifier.add(tf.keras.layers.Dense(16, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(num_classes,activation='softmax'))

    return supervised_classifier


test_dataset = tf.data.Dataset.from_tensor_slices(testing_paths)

test_dataset= test_dataset.map(read_and_preprocess_image)
test_dataset= test_dataset.batch(batch_size)

test_embeddings_output =[]
ctr=0
for mini_batch in test_dataset:
  test_embeddings= contrastiveClusteringModel.call_contrastive(mini_batch)
  for vec in test_embeddings:
    test_embeddings_output.append(vec.numpy())
  ##if(ctr>10):
    ##break
  ctr+=1

def encode_values_to_numbers(actual_labels):
    return np.where(pd.get_dummies(actual_labels).values ==1)[1]

test_embeddings_output= np.array(test_embeddings_output)
##x_true= pd.get_dummies(testing_labels).values
#percentages=[0.3, 0.5, 0.6, 0.8,0.9,1.0]
percentages= [1.0]
for percentage in percentages:
    gc.collect()
    clustering_dataset = get_dataset(image_paths, percentage)
    clustering_datapoints= get_embeddings(clustering_dataset)
    train_cluster_dataset= np.array(clustering_datapoints)

    train_y= pd.get_dummies(training_labels[:round(percentage*total_num_images)]).values

    supervised_classifier= get_supervised_classifier()
    supervised_classifier.compile(loss='categorical_crossentropy',
                optimizer='adam',
                metrics=['accuracy'])
    history = supervised_classifier.fit(train_cluster_dataset,train_y,batch_size= 32,epochs= 1000,validation_split=0.2)

    predictions = supervised_classifier(test_embeddings_output)
    e2= encode_values_to_numbers(testing_labels)
    e1= []
    for i in predictions:
        print(i)
        e1.append(np.where(i==max(i))[0][0])
    
    RocCurveDisplay.from_predictions(e1, e2);

fig= RocCurveDisplay.from_predictions(e1, e2).figure_

fig.savefig('ROC_imagenet.png')

from sklearn.metrics import PrecisionRecallDisplay

PrecisionRecallDisplay.from_predictions(e2, e1).figure_.savefig('PR_imagenet.png')

#supervised_classifier= tf.keras.models.load_model('/content/sup_class_bin.h5', compile= False)

from tensorflow.keras.optimizers import SGD
from sklearn.metrics import precision_recall_fscore_support
'''supervised_classifier.compile(loss='categorical_crossentropy',
            optimizer=SGD(learning_rate=0.01, momentum=0.95, nesterov=True,clipnorm=1.0),
            metrics=['accuracy'])'''
f1_scores= []
accuracies=[]

def get_dataset(image_paths,percentage):
    total_num_images= len(image_paths)
    clustering_dataset= tf.data.Dataset.from_tensor_slices(image_paths[:round(percentage*total_num_images)])
    print(len(image_paths[:round(percentage*total_num_images)]))
    clustering_dataset= clustering_dataset.map(read_and_preprocess_image)
    clustering_dataset= clustering_dataset.batch(clustering_dataset_batch, drop_remainder= False)

    return clustering_dataset

def get_embeddings(clustering_dataset):
    clustering_datapoints=[]
    ctr=0
    for datapoint_batch in clustering_dataset:
      embeddings= contrastiveClusteringModel.call_contrastive(datapoint_batch)
      for datapoint in embeddings:
        clustering_datapoints.append(datapoint.numpy())
      ctr+=1

    return np.array(clustering_datapoints)

def get_supervised_classifier2():
  embedding_layer= tf.keras.models.load_model('/content/sup_class_bin.h5', compile= False)
  added_layer= tf.keras.layers.Dense(32,activation = 'relu')(embedding_layer.output)
  embedding_layer2= Model(embedding_layer.input, added_layer,name='embedding_layer')
  return embedding_layer2

def get_supervised_classifier():
    supervised_classifier = tf.keras.Sequential()
    supervised_classifier.add(tf.keras.layers.Dense(256, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(256, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(128))
    supervised_classifier.add(tf.keras.layers.Dense(128, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(64, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(32, activation="relu"))
    supervised_classifier.add(tf.keras.layers.Dropout(0.4))
    supervised_classifier.add(tf.keras.layers.Dense(16, activation="relu"))
    supervised_classifier.add(tf.keras.layers.BatchNormalization())
    supervised_classifier.add(tf.keras.layers.Dense(num_classes,activation='softmax'))

    return supervised_classifier


test_dataset = tf.data.Dataset.from_tensor_slices(testing_paths)

test_dataset= test_dataset.map(read_and_preprocess_image)
test_dataset= test_dataset.batch(batch_size)

test_embeddings_output =[]
ctr=0
for mini_batch in test_dataset:
  test_embeddings= contrastiveClusteringModel.call_contrastive(mini_batch)
  for vec in test_embeddings:
    test_embeddings_output.append(vec.numpy())
  ##if(ctr>10):
    ##break
  ctr+=1

def encode_values_to_numbers(actual_labels):
    return np.where(pd.get_dummies(actual_labels).values ==1)[1]

test_embeddings_output= np.array(test_embeddings_output)
##x_true= pd.get_dummies(testing_labels).values
#percentages=[0.3, 0.5, 0.6, 0.8,0.9,1.0]
percentages= [1.0]

for _ in range(10):
      percentage=1.0
      gc.collect()
      clustering_dataset = get_dataset(image_paths, percentage)
      clustering_datapoints= get_embeddings(clustering_dataset)
      train_cluster_dataset= np.array(clustering_datapoints)

      train_y= pd.get_dummies(training_labels[:round(percentage*total_num_images)]).values

      supervised_classifier= get_supervised_classifier()

      supervised_classifier.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
      history = supervised_classifier.fit(train_cluster_dataset,train_y,batch_size= 32,epochs= 2000,validation_split=0.2)

      evaluate_output = supervised_classifier.evaluate(test_embeddings_output, pd.get_dummies(testing_labels).values ==1)
      print(evaluate_output)
      accuracies.append(evaluate_output[1])

      predictions = supervised_classifier(test_embeddings_output)

      e2= encode_values_to_numbers(testing_labels)

      e1= []
      for i in predictions:
          e1.append(np.where(i==max(i))[0][0])

      output = precision_recall_fscore_support(e1,e2, average='weighted')
      print(output[2])
      f1_scores.append(output[2])
      #accuracies.append()
print(accuracies)
print(f1_scores)

print(f1_scores)

print(accuracies)

e2

print("Animesh Hogaya")

print(accuracies)

print(f1_scores)

clustering_dataset= tf.data.Dataset.from_tensor_slices(image_paths)
clustering_dataset= clustering_dataset.map(read_and_preprocess_image)
clustering_dataset= clustering_dataset.batch(clustering_dataset_batch, drop_remainder= False)

clustering_datapoints=[]
ctr=0
for datapoint_batch in clustering_dataset:
  embeddings= contrastiveClusteringModel.call_contrastive(datapoint_batch)
  for datapoint in embeddings:
    clustering_datapoints.append(datapoint.numpy())
  ctr+=1

train_cluster_dataset= np.array(clustering_datapoints)

train_cluster_dataset.shape

train_y= pd.get_dummies(training_labels).values

supervised_classifier = tf.keras.Sequential()
supervised_classifier.add(tf.keras.layers.Dense(256, activation="relu"))
supervised_classifier.add(tf.keras.layers.BatchNormalization())
supervised_classifier.add(tf.keras.layers.Dense(256, activation="relu"))
supervised_classifier.add(tf.keras.layers.BatchNormalization())
supervised_classifier.add(tf.keras.layers.Dense(128))
supervised_classifier.add(tf.keras.layers.Dense(128, activation="relu"))
supervised_classifier.add(tf.keras.layers.BatchNormalization())
supervised_classifier.add(tf.keras.layers.Dense(64, activation="relu"))
supervised_classifier.add(tf.keras.layers.BatchNormalization())
supervised_classifier.add(tf.keras.layers.Dense(32, activation="relu"))
supervised_classifier.add(tf.keras.layers.Dropout(0.4))
supervised_classifier.add(tf.keras.layers.Dense(16, activation="relu"))
supervised_classifier.add(tf.keras.layers.BatchNormalization())
supervised_classifier.add(tf.keras.layers.Dense(num_classes,activation='softmax'))

from tensorflow.keras.optimizers import SGD
'''supervised_classifier.compile(loss='categorical_crossentropy',
            optimizer=SGD(learning_rate=0.01, momentum=0.95, nesterov=True,clipnorm=1.0),
            metrics=['accuracy'])'''
supervised_classifier.compile(loss='categorical_crossentropy',
            optimizer='adam',
            metrics=['accuracy'])

train_cluster_dataset.shape

train_y.shape

history_2 = supervised_classifier.fit(train_cluster_dataset,train_y,batch_size= 16,epochs= 20000,validation_split=0.1)

supervised_classifier.summary()

"""## Importing and initializing Test Dataset """

test_dataset = tf.data.Dataset.from_tensor_slices(testing_paths)

test_dataset= test_dataset.map(read_and_preprocess_image)
test_dataset= test_dataset.batch(batch_size)

pd.get_dummies(testing_labels).values

def encode_values_to_numbers(actual_labels):
    return np.where(pd.get_dummies(actual_labels).values ==1)[1]

encoded_labels = encode_values_to_numbers(testing_labels)

testing_labels= np.array(testing_labels)

history_2.history.keys()

accuracy=[]
window= 1000
y= history_2.history['accuracy']
for ind in range(len(y)):
  accuracy.append(np.mean(y[ind:ind+window]))

loss=[]
window= 1000
y= history_2.history['loss']
for ind in range(len(y)):
  loss.append(np.mean(y[ind:ind+window]))

val_loss= []
window= 1000
y= history_2.history['val_loss']
for ind in range(len(y)):
  val_loss.append(np.mean(y[ind:ind+window]))

val_accuracy=[]
window= 1000
y= history_2.history['val_accuracy']
for ind in range(len(y)):
  val_accuracy.append(np.mean(y[ind:ind+window]))

np.sort(np.unique(y))

supervised_classifier.save('sup_class_bin_2.h5')



import matplotlib.pyplot as plt
plt.plot(accuracy[:16000], label= 'loss',color='blue')
plt.plot(val_accuracy[:16000], label= 'val-loss',color='red')
plt.xlabel('epochs')
##plt.ylabel('accuracy')
##plt.plot(average_y_2, label='loss', color='red')
plt.legend()
ax= plt.gca()
ax.axes.xaxis.set_ticklabels([])
plt.show()
#plt.plot(history.history['loss'])

history.history.keys()

"""## Saving Model Weights"""

embedding_layer.save('/content/drive/MyDrive/embedding_layer_series_3')

"""## *Generating Predictions from the Test Dataset and clustering algos* """

embeddings_output =[]
ctr=0
for mini_batch in test_dataset:
  embeddings= contrastiveClusteringModel.call_contrastive(mini_batch)
  for vec in embeddings:
    embeddings_output.append(vec.numpy())
  ##if(ctr>10):
    ##break
  ctr+=1

import pickle

##with open('/content/drive/MyDrive/embeddings_series_output','wb') as f:
  ##pickle.dump(embeddings_output,f)

embeddings_output= np.array(embeddings_output)

x_true= pd.get_dummies(testing_labels).values

predictions = supervised_classifier(embeddings_output)

predictions.shape

supervised_classifier.evaluate(embeddings_output, pd.get_dummies(testing_labels).values ==1)

##e1= encode_values_to_numbers(embeddings_output)
e2= encode_values_to_numbers(testing_labels)

e1= []
for i in predictions:
  if(max(i) == i[0]):
    e1.append(0)
  else:
    e1.append(1)

e1

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns
sns.heatmap(confusion_matrix(e1,e2),annot=True,fmt='d')
##ConfusionMatrixDisplay(confusion_matrix(e1,e2)).plot()s

matrix = confusion_matrix(e1,e2)
tp= matrix[1][1]
fp= matrix[1][0]
fn = matrix[0][1]

precision = tp/(tp+fp)

recall = tp/(tp+fn)

f1_score= (2*precision*recall/(precision+recall))

with open('history_2','wb') as f:
  pickle.dump(history_2.history,f)

precision

recall

f1_score

"""## NMI Score / Adjusted Rand Score"""

from sklearn.metrics.cluster import normalized_mutual_info_score
from sklearn.metrics.cluster import adjusted_rand_score
from sklearn.metrics.cluster import fowlkes_mallows_score

def generate_output(actual_labels, predicted_labels):
  actual_labels= np.reshape(actual_labels, actual_labels.shape)
  nmi_score= normalized_mutual_info_score(actual_labels,predicted_labels)
  rand_score= adjusted_rand_score(actual_labels, predicted_labels)
  fowlkes_score= fowlkes_mallows_score (actual_labels, predicted_labels)

  print("NMI score --> "+ str(nmi_score))
  print("RAND score --> "+ str(rand_score))
  print("Fowlkes Score --> "+ str(fowlkes_score))

print("MKMC Output --> ")
generate_output(encoded_labels,predictions_mkmc)

print("KMEANS output --> ")
generate_output(encoded_labels,predictions_kmeans)

print("DBSCAN output --> ")
generate_output(encoded_labels, predictions_dbscan)

gc.collect()

embedding_layer.summary()

99.22

66.74

